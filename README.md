# Optimized Shifts

Librer铆a soluci贸n escrita en Python para prueba t茅cnica de NeuralWorks.

Consta de un servicio tipo API REST, una cola de procesamiento en Celery y un websocket para notificar cuando el procesamiento se ha completado.

## Contexto

Se requiere apoyar con la creaci贸n de turnos entre personas con viajes similares. Se ha proporciado un archivo `.csv` con una muestra de los datos a considerar. Se ha requerido:

1. Procesos automatizados para ingerir y almacenar datos **bajo demanda**
    - Se requiere agrupar los viajes que son similares en terminos de origen, destino y hora del d铆a.
2. Servicio que proporcione:
    - Promedio semanal de la cantidad de viajes para un 谩rea definida por un bounding box y la regi贸n.
    - Informe de la ingesta de datos **sin utilizar polling**.
3. Soluci贸n escalabre a **100 millones de entradas**.
4. Soluci贸n escrita en **Python** usando una base de datos **sql**.
5. **Incluir contenedores** en la soluci贸n, dibujar como configurar la aplicaci贸n en **GCP**

## Supuestos

Dada las instrucciones del challenge, se consideraron los siguientes supuestos:

1. Los datos pueden cargarse m谩s de una vez (se puede inicializar con un `.csv` pero se espera poder almacenar m谩s datos en el futuro).
    - Bajo este supuesto, se implement贸 dos formas de poder agregar nuevos datos: A trav茅s de archivos (`.csv` con el esquema propuesto en la muestra proporcionada), y v铆a `POST` a una `API`.  
2. Se asume como servicio una API REST:
    - As铆 la petici贸n al promedio semanal se hace a trav茅s de la API, y las notificaciones respecto a la ingesta de datos se hacen a trav茅s de un websocket (as铆 evitamos polling).

## Resumen General de los Hitos

-  Procesos automatizados para ingerir y almacenar datos bajo demanda:
    - El usuario debe gatillar el proceso mediante una petici贸n `POST` con la ubicaci贸n del archivo, esto es intencional puesto que se busca imitar el comportamiento del programa ante un evento de procesar un archivo con su ubicaci贸n. Es f谩cilmente escalable a la nube usando `Pub/Sub Notifications` de `GCP`. As铆 gatillamos un `Cloud Function` con el procesado cuando se cree un nuevo archivo en el bucket.
    - No se realiz贸 la agrupaci贸n. Esto fue en honor al tiempo debido a que no alcanc茅 a pensar en una forma de almacenar la agrupaci贸n en la base de datos. Llegu茅 a la siguiente consulta:

    ```sql
    -- Esta consulta retorna la agrupaci贸n solicitada, es decir, con esto puedo saber la cantidad de viajes similares agrupados por una cierta distancia a una cierta hora, pero pierdo la informaci贸n de CUALES son los viajes agrupados.

    -- @Distance: Distancia m谩xima en la que los viajes deben estar para considerarse similares
    -- @Timelapse: Tiempo m谩ximo en lo que los viajes pueden estar distanciados para considerarse similares

    -- Por ejemplo, podr铆amos considerar que un viaje es similar a otro si
    -- @Distance es 0.5 (KM) y @Timelapse son 300 (segundos)
    SELECT region, ST_ClusterWithin(v_trip::geometry, @Distance) 
    FROM (
        SELECT id, region, origin - destination AS v_trip, 'timestamp', source, SUM(nearest) OVER (ORDER BY t ASC) AS time_group
        FROM (
            SELECT dts.*, CASE WHEN dt > @Timelapse THEN 1 ELSE 0 END AS nearest
            FROM (
                    SELECT *, 'timestamp' AS t, lag('timestamp') OVER (ORDER BY 'timestamp' ASC) AS t_prev,
                        extract(epoch FROM 'timestamp' - lag('timestamp') OVER (ORDER BY 'timestamp' ASC)) AS dt
                    FROM travels
            ) dts
        ) AS nearest_group
    ) AS t_group
    GROUP BY region, time_group
    ORDER BY region
    ```
    Estuve manejando algunas soluciones como la creaci贸n de una vista materializada en postgres que se fuera actualizando cada vez que se insertara un viaje, pero hacer esto supone un costo muy alto y no soluciona el problema de saber cuales fueron los viajes agrupados.

    Por lo que decid铆 no implementarlo, sin embargo lo adjunto ac谩.
-  Servicio que proporcionen el promedio semanal de la cantidad de viajes para un 谩rea definida por un bounding box y la regi贸n, y un informe de la ingesta de datos **sin utilizar polling**.
    - Realizado con exito via soluci贸n tipo `API` en conjunto con `Websockets` para la notificaci贸n de la ingesta de datos.
-  Soluci贸n escalabre a **100 millones de entradas**.
    - El procesamiento de datos (ingesta de datos) puede ser colocada en una `Cloud Function`, a su vez que la `API`. Por lo que soluciona el problema del escalado.
-  Soluci贸n escrita en **Python** usando una base de datos **sql**.
-  **Incluir contenedores** en la soluci贸n, dibujar como configurar la aplicaci贸n en **GCP**
    - La descripci贸n de los contenedores se encuentra m谩s abajo, se adjunta a continuaci贸n diagrama de configuraci贸n en **GCP**:

## Levantamiento de la app

Se debe contar con `docker` y `docker compose` instalados en la m谩quina a ejecutar.

En este repositorio se encuentran todos los archivos para poder ejecutar la aplicaci贸n.

Solo se debe crear un archivo `.env` con la siguiente informaci贸n:

```bash
BROKER_URL="redis://redis:6379/0"
POSTGRES_HOST="postgres"

POSTGRES_USER="cualquier_usuario"
POSTGRES_PASSWORD="cualquier_password"
POSTGRES_DB="cualquier_nombre_para_la_db"
```

Y guardarlo en la carpeta raiz del repositorio.

Finalmente levantar el proyecto con `docker compose up -d`

## Descripci贸n de la soluci贸n

La soluci贸n contempla una API para consultar las estadisticas solicitadas, una cola de procesamiento (celery) para procesar los archivos y almacenarlos en la base de datos, y un websocket para el notificado del procesamiento.

Espec铆ficamente la soluci贸n emplea los siguientes servicios:

- API: Proporciona un endpoint para consultar el promedio semanal solicitado, a su vez que proporciona un endpoint para subir archivos via `.csv` (que delega al servicio de Celery retornando una ID para seguir el estado del procesamiento) y un websocket en el que recibiremos notificaciones del estado de los procesamientos (podemos seguirlo a trav茅s de la ID descrita anteriormente).
- Celery: Cola de procesamiento, recibe tareas desde la API para buscar, descargar y procesar los archivos requeridos, subiendo los datos a Postgres y enviando una notificaci贸n del estado del procesamiento a una cola Redis para su distribuci贸n.
- Redis: Base de datos key-value que es utilizada como sistema de publicador / subscriptor, en el que Celery publicar谩 los estados de los procesamientos y el websocket se subscribir谩 para notificar a todos los usuarios conectados a el sobre el estado de procesamiento.
- Postgresql: Base de datos elegida para el desaf铆o, dado que los datos a procesar son geom茅tricos, Postgresql tiene una buena comunidad con Postgis para este tipo de datos.

A continuaci贸n se describen en detalle cada uno de ellos:

### API

Este servicio proporciona los siguientes endpoints:

- `[GET] /api/v1/trips/stats`: Obtiene el promedio semanal de la cantidad de viajes para un bounding box y regi贸n definidas. Tiene como par谩metros obligatorios:
    - `region`: Nombre de la regi贸n (Ejemplo: `Paris`)
    - `nortest`: Esquina superior derecha del bounding box, en formato `x,y` (Ejemplo: `1.25,3.43`)
    - `southest`: Esquina inferior izquierda del bounding box, en formato `x,y` (Ejemplo: `2.34,3.45`)

    Ejemplo en python para petici贸n:
    ```py
    import requests
    from urllib.parse import urlencode

    q = {
        "nortest": "3.5,0.5",
        "southest": "3,0",
        "region": "Paris",
    }

    response = requests.get("http://localhost:8000/api/v1/trips/stats?" + urlencode(q))
    response.json()
    >>> { "mean": 3 }
    ```
- `[POST] /api/v1/trips`: Creaci贸n de viajes, esto puede ser mediante JSON o la url de un archivo `.csv` con el formato de la muestra proporcionada. Este endpoint espera los siguientes datos:
    - `data_type`: Tipo de dato a enviar, puede ser `json` (insertar谩 los datos proporcionados en el campo `data`), `gcp` (Ordenar谩 a celery la busqueda de un archivo `.csv` en `Cloud Storage` usando la ruta proporcionada en `data`) o `mocked` (Simula ser `gcp` pero en vez de ir a la nube a buscar el archivo, lo busca en disco)
    - `data`: URL o JSON con formato de puntos especificados a continuaci贸n.
    
    Ejemplo de petici贸n usando `mocked`
    ```py
    import requests
    
    q = {
        "data_type": "mocked",
        "data": "/app/files/trips.csv"
    }

    response = requests.post("http://localhost:8000/api/v1/trips", json=q)
    response.json()
    >>> { "message": "Task is processing: 877439ae-df3b-47e1-b2ff-ea00f70d9077", "metadata": "PENDING" }

    ```
    Ejemplo de petici贸n usando `json`
    ```py
    import requests
    
    q = {
        "data_type": "json",
        "data": [
            {
                "region": "Paris",
                "origin": [
                    1.0,
                    1.0
                ],
                "destination": [
                    1.5,
                    1.0
                ],
                "timestamp": "2023-01-01 00:00:00",
                "source": "from_api_point"
            }
        ]
    }

    response = requests.post("http://localhost:8000/api/v1/trips", json=q)
    response.json()
    >>> { "message": "Points inserted" }
    ```
- `[WS] /api/v1/trips/live`: Websocket que emite mensajes cuando la cola de procesamiento ha terminado de procesar.
    - Un cliente conectado recibir谩 mensajes cada vez que un procesado de archivos gatillado por una petici贸n `POST` a la API ha terminado.
    
    Ejemplo para escuchar el websocket usando python
    ```py
    import json
    import asyncio
    import websockets

    async def hello():
        uri = "ws://localhost:8000/api/v1/trips/live"
        async with websockets.connect(uri) as websocket:
            while True:
                message = json.loads(await websocket.recv())
                if message["type"] == "ping":
                    # Para detectar si seguimos conectados
                    await websocket.send(json.dumps({"type": "pong"}))
                    continue
                elif message["type"] == "notification":
                    print(message["data"])

    if __name__ == "__main__":
        asyncio.run(hello())
    ```

    Si hacemos una petici贸n `POST` de tipo `mocked` o `gcp` como en el ejemplo del punto anterior, recibiremos un mensaje con la ID de la tarea de procesamiento (`877439ae-df3b-47e1-b2ff-ea00f70d9077` en el ejemplo anterior), por lo que una vez que est茅 listo, recibiremos en el websocket el siguiente mensaje:

    ```json
    {
        "task_id": "877439ae-df3b-47e1-b2ff-ea00f70d9077",
        "status": "DONE",
        "message": "Succesfully inserted data to postgis"
    }
    ```

### Celery

Servicio que descarga, lee y procesa un archivo `.csv`.

Para esto:
- Descarga el archivo solicitado: 
    - Si la petici贸n fue de tipo `mocked`, buscar谩 en disco el archivo, usando como ruta lo proporcionado en `data`
    - Si la petici贸n fue de tipo `gcp`, buscar谩 en el bucket de GCP en funci贸n de la ruta proporcionada en `data` **(Este no est谩 implementado, se utiliza `mocked` en su lugar para mostrar un propotipo de lo que se puede hacer)**
    - Notese que es facil agregar m谩s tipos de procesamiento, como puede ser Amazon S3 u otros.
- Lee el CSV y lo procesa:
    - Para esto convierte las columnas geom茅tricas (`origin_coord`, `destination_coord`) a floats y parsea la columna `datetime` a, en efecto, un `datetime`
    - Luego queda propuesto una agrupaci贸n para almacenar los clusteres en Postgres, en honor al tiempo no se efectu贸 dicha agrupaci贸n y solo se insertan los datos en una tabla similar al formato de la muestra.
- Inserta los datos en Postgres.
- Publica en `Redis` el resultado del procesamiento.

### Redis

Base de datos key-value en memoria, escogida para implementar sistema pub/sub, en el que `Celery` publicar谩 los resultados de los procesamientos, y un `websocket` actuar谩 como subscriptor para notificar a los usuarios sobre el estado del procesamiento.

### Resumen

Lo anterior se puede resumir en el siguiente diagrama:

![image](https://github.com/Keviinplz/optimized-shifts/assets/41240999/e189e3e8-68ef-4fbb-bfd2-24856e617066)

## Ok, quiero probar todo lo anterior...

Para esto debes levantar la aplicaci贸n como est谩 descrito en el apartado de `Levantamiento de la app`, se expondr谩 la `API` en el puerto `8000`, por lo que puedes hacer consultas en `http://localhost:8000/api/v1`

### Para probar la ingesta de datos via archivos

Guarda un archivo `.csv` con el mismo formato que conten铆a el archivo de muestra en `fileupload`, esto har谩 que el archivo est茅 ubicado dentro del contenedor en `/app/files`, por ejemplo, si guardaste un archivo `prueba.csv` (es decir `/fileupload/prueba.csv`) entonces la ruta dentro del contenedor ser谩 `/app/files/prueba.csv`

Ahora env铆a una petici贸n `POST` a `http://localhost:8000/api/v1/trips` con los siguientes datos:
```json
{
    "data_type": "mocked",
    "data": "/app/data/prueba.csv"
}
```

Recibir谩s una respuesta con la `id` de la tarea de procesamiento (es decir, tu archivo ahora se est谩 procesando y guardando en postgres)

Si est谩s conectado al websocket como fue descrito anteriormente, recibir谩s una notificaci贸n en cuanto el procesamiento haya finalizado `:)`

### Para probar la ingesta de datos via JSON

Basta enviar una petici贸n `POST` a `http://localhost:8000/api/v1/trips` con los siguientes datos:
```json
{
        "data_type": "json",
        "data": [
            {
                "region": "nombre de la regi贸n",
                "origin": [
                    1.0, 
                    1.0
                ],
                "destination": [
                    1.5,
                    1.0
                ],
                "timestamp": "YYYY-mm-dd HH:MM:SS",
                "source": "similar a datasource"
            }
        ]
    }
```

Donde `origin` y `destination` es una tupla de dos floats (x, y). Notese que se est谩 enviando un arreglo, por lo que podemos mandar m谩s de un viaje si se quisiera

Recibiras una respuesta con la confirmaci贸n de que los datos fueron almacenados en la base de datos.

### Para probar el promedio semanal

Basta enviar una petici贸n `GET` a `http://localhost:8000/api/v1/trips/stats` con los par谩metros definidos anteriormente, recibir谩s una respuesta con el promedio si es que existe, o `None` en el caso de que no hayan datos.